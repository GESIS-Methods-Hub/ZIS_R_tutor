---
title: "Basic Analysis for Scale Archiving"
subtitle: "*ZIS R-Tutorials*"
logo: pics/zis_logo.svg
bibliography: basic.bib

author:
  - name: Julian Urban
    affiliation: "GESIS – Leibniz Institute for the Social Sciences"
  - name: David Grüning
    affiliation: ""
  - name: Piotr Koc
    affiliation: ""

   
date: 2024-07-01
date-format: "DD.MM.YYYY"
date-modified	: last-modified
format:
  html:
    code-overflow: wrap
    code-copy: true
    toc: true
    toc-location: left
    theme: cosmo
    html-math-method: katex
    css: technical/styles.css
    template-partials:
       - technical/title-block.html
    
license: "CC BY-NC 4.0"
citation: 
    type: "document"
    title: |
        Basic Analysis for Scale Archiving
    author:
       - name: Julian Urban
       - name: Piotr Koc
       - name: David Grüning
    issued: 2024
    container-title: ZIS R-tutorials
    publisher: GESIS – Leibniz Institute for the Social Sciences 
    URL: https://zis.gesis.org/infotexte/GuidelineMaterials.html
    
---
## Introduction

The following tutorial presents the basic analysis required for an instrument to be archived in the Open Access Repository for Measurement Instruments (ZIS). As an example, we use a scale with continuous indicators, so not all parts of the analysis are appropriate for instruments with categorical indicators. We point this out whenever relevant. The treatment of categorical indicators is covered in a separate tutorial. 

## Data Preparation & Descriptive Analysis
In this tutorial, we will use the `HolzingerSwineford1939` data set, which contains mental ability test scores of seventh- and eighth-grade children from two different schools (Pasteur and Grant-White). 

```{r}
#| message: false
  library(lavaan)
  library(psych)
  library(dplyr)

# Loading the data
Data <- lavaan::HolzingerSwineford1939
```

First, let's compute the descriptives for the nominal variables --- the counts. You can compute the counts using the `table()` function. If you have multiple variables, you can use a loop that iterates over the elements of the `nominal_variables` vector and produces as many tables with counts as there are variables in that vector. 

```{r}
# Define nominal variables
nominal_variables <- c("sex", "school", "grade")

# Count for a single variable
table(Data$sex,
      useNA = "always")

# Count for multiple variables
nominal_sample_statistics <- list()
for (variable in nominal_variables) {
  frequency_table <- table(Data[, variable],
                           useNA = "always")
  nominal_sample_statistics[[variable]] <- frequency_table
}
nominal_sample_statistics

```
For continuous variables, we compute the mean, standard deviation, skewness, kurtosis, and the percentage of missing data.

```{r}
# Compute aggregated age variable of year and months
Data$age <- (Data$ageyr * 12 + Data$agemo) / 12

# Estimate mean, sd, skew, kurtosis, and percentage missing
avrg_ <- mean(Data$age, na.rm = TRUE)
sd_ <- sd(Data$age, na.rm = TRUE)
skw_ <-psych::skew(Data$age, na.rm = TRUE)
krtss_<- psych::kurtosi(Data$age, na.rm = TRUE)
mis_ <- sum(is.na(Data$age)) / nrow(Data)

smmry <- data.frame(
  var = "age",
  avrg_ = avrg_,
  sd_ = sd_,
  skw_ = skw_,
  krtss_ = krtss_,
  mis_ = mis_
)

# Format the numeric columns to 2 decimal places using sprintf
smmry <- smmry %>%
  mutate(across(c(avrg_, sd_, skw_, krtss_), 
                ~ sprintf("%.2f", .)))

# Rename columns
colnames(smmry) <- c("Variable", "Mean", "Standard Deviation", "Skewness", "Kurtosis", "% Missing Data")
smmry
```

## Item Analysis
### Dimensionality Assessment
First, we build a look-up table where items are assigned to different subscales. We will use the table for the subsequent analyses in this section. 

```{r}
# Build lookup table for required items
lookup_table <- data.frame(item = paste("x", c(1:9), sep = ""),
                           subscale = c(rep(c("visual", "textual", "speed"),
                                            each = 3))
                           )
```
#### Exploratory Factor Analysis 
To decide how many latent dimension to extract, we will first use parallel analysis (for the factor solution, not principle components) and exploratory factor analysis. We run parallel analysis using the following syntax: 

```{r}
#| message: false
#| label: fig-figpar
set.seed(8576456)
# Conduct parallel analysis display screeplot
parallel_analyses_efa <- psych::fa.parallel(Data[ , unlist(lookup_table$item)],
                                            fa = "fa", # Method to explore dimensionality: efa
                                            fm = "minres", nfactors = 1, SMC = F,
                                            n.iter = 30, # quant = .95,
                                            cor = "cor")                            
```
::: {.column-margin}
For categorical data, you would need to change the `cor =` argument in the `fa.parallel()` function to `"poly"` and use polychoric correlations.  
:::

The idea behind parallel analysis in exploratory factor analysis (EFA) involves comparing the eigenvalues from your actual data to those from randomly generated data to determine the number of factors to retain. The random datasets match your actual dataset in terms of sample size and number of variables. Eigenvalues are calculated for both the real data and the random data. This process is repeated multiple times to generate a distribution of eigenvalues for the random data. 

The key step is then to compare the eigenvalues from your actual data with the mean (or sometimes the 95th percentile) of the eigenvalues from the random datasets. You retain those factors where the actual eigenvalue exceeds the corresponding eigenvalue from the random data. In our case,  @fig-figpar with a scree plot suggests that we should extract three factors. 

::: {.callout-important appearance="simple"}
## Be careful
Quite often researchers use the Kaiser-1 rule to decide the number of latent factors to extract. That is, they check how many eigenvalues are greater than 1. This method has been shown not be robust and result in extracting too many latent dimensions [see, @russell_search_2002; @van_der_eijk_risky_2015]. Hence, you should probably refrain from using it. 
:::

Knowing how many factors to extract, we will estimate now an EFA model with three factors using the oblique rotation and minimal residuals (a.k.a. ordinary least squares) as the extraction method^[If you are interested in the details of exploratory factor analysis, you might want to check the book by @fabrigar_exploratory_2012]. 

```{r}
# Estimate exploratory factor analyses
efa <- psych::fa(Data[ , unlist(lookup_table$item)],
                 fm = "pa",
                 nfactors = 3,
                 rotate = "oblimin",
                 scores = "regression", oblique.scores = F,
                 SMC = TRUE,
                 cor = "cor")

```
The output of the `fa()` function is very detailed, potentially overwhelming, so we won't be showing it in the whole. Instead we will focus on the key elements, starting with the matrix of factor loadings. 
```{r}
# matrix of factor loadings
round(efa[["loadings"]], digits = 2)
```
By looking at the matrix we can see that items `x1-x3` have high loadings on the factor `PA3`, items `x4-x6`  have 


```{r}
# factor intercorrelation
round(efa[["Phi"]], digits = 2)

# item communalities
round(efa[["communality"]], digits = 2)

# eigen values
round(efa[["values"]], digits = 2) # or e.values?
```




```{r}
#===============================================================================
# STEP 3.2: Confirmatory factor analyses (CFA)
#-------------------------------------------------------------------------------
# Method to explore dimensionality: cfa
# Model estimator: MLR
# Handling of missing data: no missing data
# model specifications: Compare 'Define models'
# model fit indices: Compare 'Fit evaluation'

# Define models
one_fator_model <- '
g_factor =~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9
'

three_fator_model <- '
visual =~ x1 + x2 + x3
textual =~ x4 + x5 + x6
speed =~ x7 + x8 + x9
'

three_factor_tau_model <- '
visual =~ a*x1 + a*x2 + a*x3
textual =~ b*x4 + b*x5 + b*x6
speed =~ c*x7 + c*x8 + c*x9
'

# Estimate cfa
# One factor model
one_factor_cfa <- lavaan::cfa(model = one_fator_model,
                              data = Data,
                              estimator = 'mlr',
                              std.lv = TRUE)
lavaan::summary(one_factor_cfa,
                fit.measures = TRUE,
                standardized = TRUE)

# Three factor model
three_factor_cfa <- lavaan::cfa(model = three_fator_model,
                                data = Data,
                                estimator = 'mlr',
                                std.lv = TRUE)
lavaan::summary(three_factor_cfa,
                fit.measures = TRUE,
                standardized = TRUE)

# Three factor model model with essential tau equivalence
three_factor_tau_cfa <- lavaan::cfa(model = three_factor_tau_model,
                                    data = Data,
                                    estimator = 'mlr',
                                    std.lv = TRUE)
lavaan::summary(three_factor_tau_cfa,
                fit.measures = TRUE,
                standardized = TRUE)

# model fit
# Define fit measures of interest
# use robust versions
fit_measures <- c("chisq", "df", "pvalue",
                  "cfi.robust", "rmsea.robust", "srmr",
                  "aic", "bic", "bic2")

# Extract model fit
round(lavaan::fitMeasures(one_factor_cfa, fit.measures = fit_measures), digits = 3)
round(lavaan::fitMeasures(three_factor_cfa, fit.measures = fit_measures), digits = 3)
round(lavaan::fitMeasures(three_factor_tau_cfa, fit.measures = fit_measures), digits = 3)

# Evaluate local model fit
# Extract residual correlaton matrix
lavaan::lavResiduals(one_factor_cfa)$cov
lavaan::lavResiduals(three_factor_cfa)$cov
lavaan::lavResiduals(three_factor_tau_cfa)$cov

# Extract standardized factor loadings
lavaan::lavInspect(one_factor_cfa, "std")$lambda

# Extract standardized factor loadings & interfactor correlation
lavaan::lavInspect(three_factor_cfa, "std")$lambda
lavaan::lavInspect(three_factor_cfa, "std")$psi

lavaan::lavInspect(three_factor_tau_cfa, "std")$lambda
lavaan::lavInspect(three_factor_tau_cfa, "std")$psi
```
